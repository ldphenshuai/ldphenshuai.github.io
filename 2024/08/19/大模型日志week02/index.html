<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大模型日志week02 | 学习杂记</title><meta name="author" content="DPDP"><meta name="copyright" content="DPDP"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="day01  了解当下大语言模型  大模型架构1. MoE(混合专家模型)：MOE是把大问题先做拆分，再逐个解决小问题，再汇总结论。模型规模是提升模型性能的关键因素之一，在有限的计算资源下，用更少的训练步数训练一个更大的模型，往往比用更多的步数训练一个较小的模型效果更佳。MoE正是基于上述的理念，它由多个专业化的子模型（即“专家”）组合而成，专家的混合不会节省任何计算，因为前向传播仍然需要评估每个">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型日志week02">
<meta property="og:url" content="https://www.dpdpblog.online/2024/08/19/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%A5%E5%BF%97week02/index.html">
<meta property="og:site_name" content="学习杂记">
<meta property="og:description" content="day01  了解当下大语言模型  大模型架构1. MoE(混合专家模型)：MOE是把大问题先做拆分，再逐个解决小问题，再汇总结论。模型规模是提升模型性能的关键因素之一，在有限的计算资源下，用更少的训练步数训练一个更大的模型，往往比用更多的步数训练一个较小的模型效果更佳。MoE正是基于上述的理念，它由多个专业化的子模型（即“专家”）组合而成，专家的混合不会节省任何计算，因为前向传播仍然需要评估每个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/07/10/bivj2kSnGuJYqP9.png">
<meta property="article:published_time" content="2024-08-19T01:16:40.000Z">
<meta property="article:modified_time" content="2024-08-30T00:46:17.687Z">
<meta property="article:author" content="DPDP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2024/07/10/bivj2kSnGuJYqP9.png"><link rel="shortcut icon" href="/img/logo2.png"><link rel="canonical" href="https://www.dpdpblog.online/2024/08/19/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%A5%E5%BF%97week02/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: DPDP","link":"链接: ","source":"来源: 学习杂记","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大模型日志week02',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-30 08:46:17'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/modify.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2024/07/10/bivj2kSnGuJYqP9.png')"><nav id="nav"><span id="blog-info"><a href="/" title="学习杂记"><span class="site-name">学习杂记</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大模型日志week02</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-08-19T01:16:40.000Z" title="发表于 2024-08-19 09:16:40">2024-08-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-30T00:46:17.687Z" title="更新于 2024-08-30 08:46:17">2024-08-30</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>32分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="大模型日志week02"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="day01"><a href="#day01" class="headerlink" title="day01"></a>day01</h2><ul>
<li><input checked="" disabled="" type="checkbox"> 了解当下大语言模型</li>
</ul>
<h3 id="大模型架构"><a href="#大模型架构" class="headerlink" title="大模型架构"></a>大模型架构</h3><h4 id="1-MoE-混合专家模型-："><a href="#1-MoE-混合专家模型-：" class="headerlink" title="1. MoE(混合专家模型)："></a>1. <strong>MoE(混合专家模型)：</strong></h4><p>MOE是把大问题先做拆分，再逐个解决小问题，再汇总结论。模型规模是提升模型性能的关键因素之一，在有限的计算资源下，用更少的训练步数训练一个更大的模型，往往比用更多的步数训练一个较小的模型效果更佳。<br>MoE正是基于上述的理念，它由多个专业化的子模型（即“专家”）组合而成，专家的混合不会节省任何计算，因为前向传播仍然需要评估每个专家，而反向传播也必须接触每个专家，但是我们可以选择由哪些专家进行回答并规范化，这代表在前向和反向传播时，只需要使用非0的专家。</p>
<h4 id="2-基于检索的模型"><a href="#2-基于检索的模型" class="headerlink" title="2. 基于检索的模型:"></a>2. <strong>基于检索的模型:</strong></h4><h5 id="检索增强生成的工作流程"><a href="#检索增强生成的工作流程" class="headerlink" title="检索增强生成的工作流程"></a>检索增强生成的工作流程</h5><ol>
<li><strong>检索：</strong><br> 首先，我们需要进行的是检索过程。在这个阶段，我们利用用户的查询内容，从外部知识源获取相关信息。具体来说，就是将用户的查询通过嵌入模型转化为向量，这样就可以与向量数据库中的其他上下文信息进行比对。通过这种相似性搜索，我们可以找到向量数据库中最匹配的前k个数据。</li>
<li><strong>增强：</strong><br> 接下来，我们进入增强阶段。在这个阶段，我们将用户的查询和检索到的额外信息一起嵌入到一个预设的提示模板中。这个过程的目的是为了提供更丰富、更具上下文的信息，以便于后续的生成过程。</li>
<li><strong>生成：</strong><br> 最后，我们进行生成过程。在这个阶段，我们将经过检索增强的提示内容输入到大语言模型（LLM）中，以生成所需的输出。这个过程是RAG的核心，它利用了LLM的强大生成能力，结合了前两个阶段的信息，生成了准确、丰富且与上下文相关的输出。</li>
</ol>
<h5 id="Naive-RAG"><a href="#Naive-RAG" class="headerlink" title="Naive RAG"></a>Naive RAG</h5><ol>
<li><strong>Indexing(离线处理)：</strong></li>
</ol>
<ul>
<li>从各种格式（PDF、HTML、Markdown、Word 等）的额外语料库中提取纯文本内容。</li>
<li>由于LLM上下文窗口的限制，比如常见的2K、4K，需要将提取的文本内容切分为不同的 chunks。</li>
<li>使用文本 embedding 模型，针对每个chunk提取相应的文本embedding。</li>
<li>将文本 embedding 和对应的 chunk 存储为索引，能一一对应，即生成chunk-embedding。</li>
</ul>
<ol start="2">
<li><strong>在线处理：</strong></li>
</ol>
<ul>
<li>Retrieval（在线处理）：</li>
<li>使用文本 embedding 模型，针对用户 query 提取 query embedding。</li>
<li>使用query embedding 与索引中的 chunk embedding 进行比对，找到最相似的 k 个 embedding。然后提取 k 个最相似 embedding 对应的 chunk。</li>
<li>Generation（在线处理）：</li>
<li>将 query 与检索到的 chunks 进行合并，将合并后的Query输入到LLM中以生成结果。</li>
</ul>
<p>RAG 是一种通过<strong>检索外部知识库</strong>(其实主要优化就是对这个知识库进行优化，提高知识粒度与检索过程优化等)来获得额外语料，并使用 ICL（In-Context-Learning，上下文学习）来改进 LLM 生成效果的范式。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image-9.png" alt="alt text"></p>
<h4 id="2-1-Advanced-RAG-在Navive-RAG的基础上做了增强"><a href="#2-1-Advanced-RAG-在Navive-RAG的基础上做了增强" class="headerlink" title="2.1 Advanced RAG(在Navive RAG的基础上做了增强)"></a>2.1 Advanced RAG(在Navive RAG的基础上做了增强)</h4><h5 id="2-1-1-Pre-Retrieval-Proess-检索前优化"><a href="#2-1-1-Pre-Retrieval-Proess-检索前优化" class="headerlink" title="2.1.1 Pre-Retrieval Proess(检索前优化)"></a>2.1.1 Pre-Retrieval Proess(检索前优化)</h5><ul>
<li>增强数据粒度：旨在提升文本标准化、一致性、事实准确性和丰富的上下文，以提高 RAG 系统的性能。比如删除不相关的信息、消除实体和数据中的歧义、更新过时文档等。</li>
<li>优化索引结构：调整块的大小以捕获相关上下文、跨多个索引路径进行查询。</li>
<li>混合检索：主要是指充分利用关键词检索、语义检索、向量检索等其他检索技术来提升检索丰富度，同时也可以保证一致性。</li>
</ul>
<h5 id="2-1-2-Post-Retrieval-Process"><a href="#2-1-2-Post-Retrieval-Process" class="headerlink" title="2.1.2 Post-Retrieval Process"></a>2.1.2 Post-Retrieval Process</h5><p>检索到的内容比较多，重要性也各不相同，如果一味地和 query 合并可能会超过 LLM 上下文限制，同时增加计算开销，也可能引入噪声，导致生成质量不佳。此时，通常需要对检索到的内容进一步处理：</p>
<ul>
<li>重排序（Re-Ranking）：这是搜索领域非常常见的手段，不过在传统搜索中通常是按相关性、质量等进行排序输出；而在 LLM 生成领域要考虑检索到文档的多样性，以及 LLM 对 Prompt 中内容所在位置的敏感度等，比如 LostInTheMiddleRanker 将最佳文档交替地放在上下文窗口的开头和结尾。</li>
<li>提示压缩（Prompt Compression）：有研究表明，检索到的文档中的噪声会对 RAG 性能产生不利影响。在后处理中，可以重点压缩不相干的上下文，突出关键段落，减少整体上下文长度。也可以用专门的模型对文档进行压缩、总结、过滤等。</li>
</ul>
<h5 id="Graph-RAG-知识图谱和RAG的结合，效果很好"><a href="#Graph-RAG-知识图谱和RAG的结合，效果很好" class="headerlink" title="Graph-RAG (知识图谱和RAG的结合，效果很好)"></a>Graph-RAG (知识图谱和RAG的结合，效果很好)</h5><p>当外部知识库为知识图谱（Neo4j存储），结合向量 + 关键字和图检索方法（被称为混合检索）。</p>
<p><strong>总结：</strong></p>
<ul>
<li>为了扩大模型规模，需要改进稠密Transformer。</li>
<li>混合专家和基于检索的方法相结合更有效。</li>
<li>如何设计更好的、可扩展的体系结构仍然是一个悬而未决的问题。</li>
</ul>
<h3 id="大模型之Adaptation"><a href="#大模型之Adaptation" class="headerlink" title="大模型之Adaptation"></a>大模型之Adaptation</h3><h4 id="为什么需要语言模型的Adaptation"><a href="#为什么需要语言模型的Adaptation" class="headerlink" title="为什么需要语言模型的Adaptation?"></a>为什么需要语言模型的Adaptation?</h4><p>下游任务与语言模型的训练任务之间的不同之处非常复杂。这些差异可以从格式、主题和时间三个方面来探讨，每个方面都可能涉及许多具体的挑战和需求。通过深入了解这些不同之处，我们可以更好地理解如何有效地适配语言模型以满足各种下游任务的需求。</p>
<ol>
<li>格式：</li>
</ol>
<ul>
<li><strong>自然语言推理（NLI）</strong>: 下游任务如NLI涉及两个句子的比较以产生单一的二进制输出。这与语言模型通常用于生成下一个标记或填充MASK标记的任务截然不同。例如，NLI的逻辑推理过程涉及多层次的比较和理解，而不仅仅是根据给定的上下文生成下一个可能的词。</li>
</ul>
<ol start="2">
<li>主题转变：</li>
</ol>
<ul>
<li><strong>特定领域的需求</strong>: 下游任务可能集中在特定的主题或领域上，例如医疗记录分析或法律文档解析。这些任务可能涉及专门的术语和知识，与模型的通用训练任务相去甚远。</li>
</ul>
<ol start="3">
<li>时间转变</li>
</ol>
<ul>
<li><strong>新知识的需求</strong>: 随着时间的推移，新的信息和知识不断涌现。例如，GPT-3在拜登成为总统之前就已训练完毕，因此可能缺乏有关他总统任期的最新信息。</li>
<li><strong>非公开信息的需求</strong>: 有时下游任务可能涉及在训练期间不公开的信息。这可能需要更多特定领域的专业知识和调整。</li>
</ul>
<h4 id="微调模型适应任务"><a href="#微调模型适应任务" class="headerlink" title="微调模型适应任务"></a>微调模型适应任务</h4><h5 id="通用的Adaptation配置"><a href="#通用的Adaptation配置" class="headerlink" title="通用的Adaptation配置"></a>通用的Adaptation配置</h5><ol>
<li><p><strong>预训练语言模型（Pre-trained LM）</strong>:<br>在适配阶段的开始，我们已经有了一个预训练的语言模型，用参数$θLM$表示。这个模型被训练来理解和生成语言，但不是特别针对任何特定任务。</p>
</li>
<li><p><strong>下游任务数据集（Downstream Task Dataset）</strong>:<br>我们获得了一组来自下游任务分布$P_{task}$的样本数据。这些数据可以是文本分类、情感分析等任务的特定实例，每个样本由输入x和目标输出y组成，如：$\left(x^{(1)}, y^{(1)}\right), \ldots,\left(x^{(n)}, y^{(n)}\right)$。</p>
</li>
<li><p><strong>适配参数（Adaptation Parameters）</strong>:<br>为了使预训练的LM适合特定的下游任务，我们需要找到一组参数$\gamma$，这组参数可以来自现有参数的子集或引入的新的参数，$\Gamma$。这些参数将用于调整模型，以便它在特定任务上的表现更好。</p>
</li>
<li><p><strong>任务损失函数（Task Loss Function）</strong>:<br>我们需要定义一个损失函数$\ell_{\text {task }}$来衡量模型在下游任务上的表现。例如，交叉熵损失是一种常见的选择，用于衡量模型预测的概率分布与真实分布之间的差异。</p>
</li>
<li><p><strong>优化问题（Optimization Problem）</strong>:<br>我们的目标是找到一组适配参数$\gamma_{\text {adapt }}$，使得任务损失在整个下游数据集上最小化。数学上，这可以通过以下优化问题表示</p>
</li>
</ol>
<p>通过这个过程，我们可以取得一组适配参数$\gamma_{\text {adapt }}$，用于参数化适配后的模型$p_{adapt}$。这样，我们就可以将通用的、任务无关的预训练语言模型适配到特定的下游任务上，以实现更好的性能。这种适配方法将模型的通用性与特定任务的效能结合在一起，既保留了模型的灵活性，又确保了在特定任务上的高效表现。</p>
<h5 id="主流的Adaptation方法"><a href="#主流的Adaptation方法" class="headerlink" title="主流的Adaptation方法"></a>主流的Adaptation方法</h5><h5 id="1-fine-tuning"><a href="#1-fine-tuning" class="headerlink" title="1. fine-tuning"></a>1. fine-tuning</h5><p>Fine-tuning（微调）使用语言模型参数$θLM$作为优化的初始化。其中，优化后的参数家族$\Gamma$包括了所有的语言模型参数和任务特定的预测头参数。与此同时，预训练的优化器状态被丢弃。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39172059/article/details/136693607">大模型微调步骤</a></p>
<h5 id="2-大模型开发工具"><a href="#2-大模型开发工具" class="headerlink" title="2. 大模型开发工具"></a>2. 大模型开发工具</h5><ol>
<li>Hugging Face</li>
</ol>
<ul>
<li>提供多种 NLP 任务的模型库，如语言翻译、文本生成和问答。</li>
<li>提供了在特定数据集上微调预训练模型的工具。</li>
<li>提供了访问和利用应用程序中预训练模型的 API。</li>
<li>提供了构建定制模型并将其部署到云端的工具。</li>
<li>提供大量预训练的NLP模型。</li>
</ul>
<ol start="2">
<li>LangChain<br>LangChain 是一个用于开发由语言模型驱动的应用程序的框架。我们相信，最强大和不同的应用程序不仅将通过 API 调用语言模型，还将：</li>
</ol>
<ul>
<li>数据感知：将语言模型与其他数据源连接在一起。</li>
<li>主动性：允许语言模型与其环境进行交互</li>
</ul>
<h2 id="day02"><a href="#day02" class="headerlink" title="day02"></a>day02</h2><h3 id="LangChain详解"><a href="#LangChain详解" class="headerlink" title="LangChain详解"></a>LangChain详解</h3><h4 id="LangChain组成"><a href="#LangChain组成" class="headerlink" title="LangChain组成"></a>LangChain组成</h4><p>LangChain 包含六部分组成，分别为：Models、Prompts、Indexes、Memory、Chains、Agents。</p>
<h5 id="1-Models"><a href="#1-Models" class="headerlink" title="1. Models"></a>1. Models</h5><p>LangChain 为使用聊天模型提供了一个标准接口。LangChain 目前支持的消息类型有<code>AIMessage</code>、<code>HumanMessage</code>、<code>SystemMessage</code> 和 <code>ChatMessage</code>，其中<code>ChatMessage</code>接受一个任意的角色参数。大多数情况下，您只需要处理 HumanMessage、AIMessage 和 SystemMessage。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入OpenAI的聊天模型，及消息类型</span></span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化聊天对象</span></span><br><span class="line">chat = ChatOpenAI(openai_api_key=<span class="string">&quot;...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向聊天模型发问</span></span><br><span class="line">chat([HumanMessage(content=<span class="string">&quot;Translate this sentence from English to French: I love programming.&quot;</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持多个消息作为输入</span></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;You are a helpful assistant that translates English to French.&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;I love programming.&quot;</span>)</span><br><span class="line">]</span><br><span class="line">chat(messages)</span><br></pre></td></tr></table></figure>

<p>如果用户问聊天模型同一个问题，对结果进行了缓存，这样就可以减少接口的调用并且也能加快接口返回的速度。提供了两种缓存方案，内存缓存方案和数据库缓存方案.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入聊天模型，SQLiteCache模块</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;your apikey&#x27;</span></span><br><span class="line"><span class="keyword">import</span> langchain</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.cache <span class="keyword">import</span> SQLiteCache</span><br><span class="line"><span class="comment"># 设置语言模型的缓存数据存储的地址</span></span><br><span class="line">langchain.llm_cache = SQLiteCache(database_path=<span class="string">&quot;.langchain.db&quot;</span>)</span><br><span class="line"><span class="comment"># 加载 llm 模型</span></span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一次向模型提问</span></span><br><span class="line">result = llm.predict(<span class="string">&#x27;tell me a joke&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二次向模型提问同样的问题</span></span><br><span class="line">result2 = llm.predict(<span class="string">&#x27;tell me a joke&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result2)</span><br></pre></td></tr></table></figure>

<h5 id="2-Embeddings"><a href="#2-Embeddings" class="headerlink" title="2. Embeddings"></a>2. Embeddings</h5><p>文本等内容嵌入成多维数组，可以后续进行相似性的计算和检索。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;your apikey&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化嵌入模型</span></span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把文本通过嵌入模型向量化</span></span><br><span class="line">res = embeddings.embed_query(<span class="string">&#x27;hello world&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<h5 id="3-LLMs"><a href="#3-LLMs" class="headerlink" title="3. LLMs"></a>3. LLMs</h5><p>LangChain继承了许多大语言模型。</p>
<h4 id="4-Propmts"><a href="#4-Propmts" class="headerlink" title="4. Propmts"></a>4. Propmts</h4><p><code>LangChain</code> 提供了 <code>PromptTemplates</code>，允许你可以根据用户输入动态地更改提示，当用户需要输入多个类似的 prompt 时，生成一个 prompt 模板是一个很好的解决方案，可以节省用户的时间和精力。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义生成商店的方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_store_names</span>(<span class="params">store_features</span>):</span><br><span class="line">    prompt_template = <span class="string">&quot;我正在开一家新的商店，它的主要特点是&#123;&#125;。请帮我想出10个商店的名字。&quot;</span></span><br><span class="line">    prompt = prompt_template.<span class="built_in">format</span>(store_features)</span><br><span class="line"></span><br><span class="line">    llm = OpenAI()</span><br><span class="line">    response = llm.generate(prompt, max_tokens=<span class="number">10</span>, temperature=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">    store_names = [gen[<span class="number">0</span>].text.strip() <span class="keyword">for</span> gen <span class="keyword">in</span> response.generations]</span><br><span class="line">    <span class="keyword">return</span> store_names</span><br><span class="line"></span><br><span class="line">store_features = <span class="string">&quot;时尚、创意、独特&quot;</span></span><br><span class="line"></span><br><span class="line">store_names = generate_store_names(store_features)</span><br><span class="line"><span class="built_in">print</span>(store_names)</span><br></pre></td></tr></table></figure>

<p>LangChainHub包含了许多可以通过LangChain直接加载的Prompt Templates。也可以通过学习他们的 Prompt 设计来给我们以启发.</p>
<h5 id="5-Few-Shot-example"><a href="#5-Few-Shot-example" class="headerlink" title="5. Few-Shot example"></a>5. Few-Shot example</h5><p>使用FewShotPromptTemplate可以更方便地使用少样本学习策略, 其中包含一组示例问题和对应的答案(few-shot examples)与PromptTemplate，它使用few-shot examples格式化PromptTemplate。当examples较多时，可以使用example_selector选择部分样例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = <span class="string">&#x27;your apikey&#x27;</span></span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, FewShotPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;word&quot;</span>: <span class="string">&quot;黑&quot;</span>, <span class="string">&quot;antonym&quot;</span>: <span class="string">&quot;白&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;word&quot;</span>: <span class="string">&quot;伤心&quot;</span>, <span class="string">&quot;antonym&quot;</span>: <span class="string">&quot;开心&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">example_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">单词: &#123;word&#125;</span></span><br><span class="line"><span class="string">反义词: &#123;antonym&#125;\n</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建提示词模版</span></span><br><span class="line">example_prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;word&quot;</span>, <span class="string">&quot;antonym&quot;</span>],</span><br><span class="line">    template=example_template,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用example_selector选择部分样例</span></span><br><span class="line">example_selector = LengthBasedExampleSelector(</span><br><span class="line">    examples=examples,</span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    <span class="comment"># 最大长度</span></span><br><span class="line">    max_length=<span class="number">25</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建小样本提示词模版</span></span><br><span class="line">few_shot_prompt = FewShotPromptTemplate(</span><br><span class="line">    examples=examples,</span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    prefix=<span class="string">&quot;给出每个单词的反义词&quot;</span>,</span><br><span class="line">    suffix=<span class="string">&quot;单词: &#123;input&#125;\n反义词:&quot;</span>,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    example_separator=<span class="string">&quot;\n&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 格式化小样本提示词</span></span><br><span class="line">prompt_text = few_shot_prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">&quot;粗&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用OpenAI</span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(llm(prompt_text))</span><br></pre></td></tr></table></figure>

<h4 id="indexes"><a href="#indexes" class="headerlink" title="indexes"></a>indexes</h4><p>索引是指对文档进行结构化的方法，以便 LLM 能够更好的与之交互。该组件主要包括：Document Loaders（文档加载器）、Text Splitters（文本拆分器）、VectorStores（向量存储器）以及 Retrievers（检索器）。</p>
<h5 id="DocumentLoaer"><a href="#DocumentLoaer" class="headerlink" title="DocumentLoaer"></a>DocumentLoaer</h5><p>指定源进行加载数据的。将特定格式的数据，转换为文本。如 CSV、File Directory、HTML。</p>
<h5 id="TexSplitter"><a href="#TexSplitter" class="headerlink" title="TexSplitter"></a>TexSplitter</h5><p>由于模型对输入的字符长度有限制，我们在碰到很长的文本时，需要把文本分割成多个小的文本片段。LangChain中最基本的分割器CharacterTextSplitter，它按照指定的分隔符（默认“\n\n”）进行分割，并且考虑文本片段的最大长度。</p>
<p>LangChain支持多个高级文本分割器如下：<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image-12.png" alt="alt text"></p>
<h5 id="VectorStores、Retrievers"><a href="#VectorStores、Retrievers" class="headerlink" title="VectorStores、Retrievers"></a>VectorStores、Retrievers</h5><p>VectorStores存储提取的文本向量，包括 Faiss、Milvus、Pinecone、Chroma 等。<br>Retrievers检索器是一种便于模型查询的存储数据的方式，LangChain 约定检索器组件至少有一个方法 get_relevant_texts，这个方法接收查询字符串，返回一组文档。</p>
<h4 id="Chains"><a href="#Chains" class="headerlink" title="Chains"></a>Chains</h4><p>LangChain将上述多个组件组合在一起以创建一个单一的、连贯的任务。例如，可以创建一个链，它接受用户输入，使用 PromptTemplate 对其进行格式化，然后将格式化的响应传递给 LLM。另外我们也可以通过将多个链组合在一起，或者将链与其他组件组合来构建更复杂的链。</p>
<p>构建chain的步骤：</p>
<blockquote>
<ol>
<li>先写一个提问的模版prompt，其中中括号{}表示你要填入的变量名称。比如：”Tell me a joke about {adjective} tomatoes.”</li>
<li>组建LLMChain示例，指定llm、prompt两个必要参数，比如chain &#x3D; LLMChain(llm&#x3D;llm, prompt&#x3D;promt,verbose&#x3D;True)。</li>
<li>启动Chain，通过chain.run传递输入的变量，res &#x3D; chain.run(product)。</li>
</ol>
</blockquote>
<h4 id="LLMChain"><a href="#LLMChain" class="headerlink" title="LLMChain"></a>LLMChain</h4><p>LLMChain（是Chains中的一种）接受一个提示模版，将模版与用户输入进行格式化，并返回LLM的响应。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, OpenAI, LLMChain</span><br><span class="line"></span><br><span class="line">prompt_template = <span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span></span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">llm_chain = LLMChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    prompt=PromptTemplate.from_template(prompt_template)</span><br><span class="line">)</span><br><span class="line">llm_chain(<span class="string">&quot;colorful socks&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>run方法和call方法的入参可以是字符串，或者字典数据等</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># call方法返回输入和输出键值，return_only_outputs表示只返回输出键值。</span></span><br><span class="line">llm_chain.call(<span class="string">&quot;corny&quot;</span>, return_only_outputs=<span class="literal">True</span>) <span class="comment">#返回结果只输出键值</span></span><br><span class="line"><span class="comment"># 输出结果 </span></span><br><span class="line">&#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;Why did the tomato turn red? Because it saw the salad dressing!&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># run方法返回的是字符串</span></span><br><span class="line">llm_chain.run(&#123;<span class="string">&quot;adjective&quot;</span>: <span class="string">&quot;corny&quot;</span>&#125;) <span class="comment">#输入一个字典</span></span><br><span class="line"><span class="comment"># 输出结果 </span></span><br><span class="line"><span class="string">&#x27;Why did the tomato turn red? Because it saw the salad dressing!&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># apply方法允许输入列表</span></span><br><span class="line">input_list = [</span><br><span class="line">    &#123;<span class="string">&quot;product&quot;</span>: <span class="string">&quot;socks&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;product&quot;</span>: <span class="string">&quot;computer&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;product&quot;</span>: <span class="string">&quot;shoes&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line">llm_chain.apply(input_list)</span><br><span class="line"><span class="comment"># 输出结果 </span></span><br><span class="line">    [&#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;\n\nSocktastic!&#x27;</span>&#125;,</span><br><span class="line">     &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;\n\nTechCore Solutions.&#x27;</span>&#125;,</span><br><span class="line">     &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;\n\nFootwear Factory.&#x27;</span>&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate方法类似于apply方法，返回的是LLMResult类型的结果。</span></span><br><span class="line">llm_chain.generate(input_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果：</span></span><br><span class="line">    LLMResult(generations=[[Generation(text=<span class="string">&#x27;\n\nSocktastic!&#x27;</span>, generation_info=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>&#125;)], [Generation(text=<span class="string">&#x27;\n\nTechCore Solutions.&#x27;</span>, generation_info=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>&#125;)], [Generation(text=<span class="string">&#x27;\n\nFootwear Factory.&#x27;</span>, generation_info=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>&#125;)]], llm_output=&#123;<span class="string">&#x27;token_usage&#x27;</span>: &#123;<span class="string">&#x27;prompt_tokens&#x27;</span>: <span class="number">36</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">55</span>, <span class="string">&#x27;completion_tokens&#x27;</span>: <span class="number">19</span>&#125;, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;text-davinci-003&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">llm_chain.predict(product=<span class="string">&quot;colorful socks&quot;</span>) <span class="comment">#入参为指定关键字参数</span></span><br></pre></td></tr></table></figure>

<h4 id="SimpleSequentialChain"><a href="#SimpleSequentialChain" class="headerlink" title="SimpleSequentialChain"></a>SimpleSequentialChain</h4><p>简单的顺序链，将输入输出链接起来。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image-13.png" alt="alt text"><br>将两个LLMChain进行组合成顺序链调用的案例：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SimpleSequentialChain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义第一个chain</span></span><br><span class="line">llm = OpenAI(temperature=<span class="number">.7</span>)</span><br><span class="line">template = <span class="string">&quot;&quot;&quot;You are a playwright. Given the title of play, it is your job to write a synopsis for that title.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Title: &#123;title&#125;</span></span><br><span class="line"><span class="string">Playwright: This is a synopsis for the above play:&quot;&quot;&quot;</span></span><br><span class="line">prompt_template = PromptTemplate(input_variables=[<span class="string">&quot;title&quot;</span>], template=template)</span><br><span class="line">synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义第二个chain</span></span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">.7</span>)</span><br><span class="line">template = <span class="string">&quot;&quot;&quot;You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Play Synopsis:</span></span><br><span class="line"><span class="string">&#123;synopsis&#125;</span></span><br><span class="line"><span class="string">Review from a New York Times play critic of the above play:&quot;&quot;&quot;</span></span><br><span class="line">prompt_template = PromptTemplate(input_variables=[<span class="string">&quot;synopsis&quot;</span>], template=template)</span><br><span class="line">review_chain = LLMChain(llm=llm, prompt=prompt_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过简单顺序链组合两个LLMChain</span></span><br><span class="line">overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行顺序链</span></span><br><span class="line">review = overall_chain.run(<span class="string">&quot;Tragedy at sunset on the beach&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="TransformChain"><a href="#TransformChain" class="headerlink" title="TransformChain"></a>TransformChain</h4><p>转换链允许我们创建一个自定义的转换函数来处理输入，将处理后的结果用作下一个链的输入。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> TransformChain, LLMChain, SimpleSequentialChain</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟超长文本</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../../state_of_the_union.txt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    state_of_the_union = f.read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义转换方法，入参和出参都是字典，取前三段</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform_func</span>(<span class="params">inputs: <span class="built_in">dict</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    text = inputs[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">    shortened_text = <span class="string">&quot;\n\n&quot;</span>.join(text.split(<span class="string">&quot;\n\n&quot;</span>)[:<span class="number">3</span>])</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;output_text&quot;</span>: shortened_text&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换链：输入变量：text，输出变量：output_text</span></span><br><span class="line">transform_chain = TransformChain(</span><br><span class="line">    input_variables=[<span class="string">&quot;text&quot;</span>], output_variables=[<span class="string">&quot;output_text&quot;</span>], transform=transform_func</span><br><span class="line">)</span><br><span class="line"><span class="comment"># prompt模板描述</span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;Summarize this text:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;output_text&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Summary:&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># prompt模板</span></span><br><span class="line">prompt = PromptTemplate(input_variables=[<span class="string">&quot;output_text&quot;</span>], template=template)</span><br><span class="line"><span class="comment"># llm链</span></span><br><span class="line">llm_chain = LLMChain(llm=OpenAI(), prompt=prompt)</span><br><span class="line"><span class="comment"># 使用顺序链</span></span><br><span class="line">sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])</span><br><span class="line"><span class="comment"># 开始执行</span></span><br><span class="line">sequential_chain.run(state_of_the_union)</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    &#x27; The speaker addresses the nation, noting that while last year they were kept apart due to COVID-19, this year they are together again.</span></span><br><span class="line"><span class="string">    They are reminded that regardless of their political affiliations, they are all Americans.&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="SequentialChain"><a href="#SequentialChain" class="headerlink" title="SequentialChain"></a>SequentialChain</h4><p>SequentialChain允许每个链具有多个输入输出，重要的是当具有多个输入时，要命名输入&#x2F;输出的变量名称。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SequentialChain</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">######################################</span></span><br><span class="line"><span class="string">### Chain1 给中文产品名称翻译成英文  ###</span></span><br><span class="line"><span class="string">######################################</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># Chain1 语言转换，产生英文产品名</span></span><br><span class="line">prompt1 = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;将以下文本翻译成英文: &#123;product_name&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line">chain1 = LLMChain(</span><br><span class="line">    <span class="comment"># 使用的大模型实例</span></span><br><span class="line">    llm=llm,</span><br><span class="line">    <span class="comment"># prompt模板</span></span><br><span class="line">    prompt=prompt1,</span><br><span class="line">    <span class="comment"># 输出数据变量名</span></span><br><span class="line">    output_key=<span class="string">&quot;english_product_name&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">##################################################</span></span><br><span class="line"><span class="string">### Chain2 根据英文产品名，生成一段英文介绍文本   ###</span></span><br><span class="line"><span class="string">##################################################</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># Chain2 根据英文产品名，生成一段英文介绍文本</span></span><br><span class="line">prompt2 = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;Based on the following product, give an introduction text about 100 words: &#123;english_product_name&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line">chain2 = LLMChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    prompt=prompt2,</span><br><span class="line">    output_key=<span class="string">&quot;english_introduce&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">###########################################</span></span><br><span class="line"><span class="string">### Chain3 产品名的语言判定(中文or英文)   ###</span></span><br><span class="line"><span class="string">###########################################</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># Chain3 找到产品名所属的语言</span></span><br><span class="line">prompt3 = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;下列文本使用的语言是什么?: &#123;product_name&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line">chain3 = LLMChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    prompt=prompt3,</span><br><span class="line">    output_key=<span class="string">&quot;language&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">#########################</span></span><br><span class="line"><span class="string">### Chain4 生成概述   ###</span></span><br><span class="line"><span class="string">#########################</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># Chain4 根据Chain2生成的英文介绍，使用产品名称原本的语言生成一段概述</span></span><br><span class="line">prompt4 = ChatPromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;使用语言类型为: &#123;language&#125; ，为下列文本写一段不多于50字的概述: &#123;english_introduce&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line">chain4 = LLMChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    prompt=prompt4,</span><br><span class="line">    output_key=<span class="string">&quot;summary&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">############################</span></span><br><span class="line"><span class="string">### 组建SequentialChain  ###</span></span><br><span class="line"><span class="string">############################</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 标准版的序列Chain,SequentialChain,其中每个chain都支持多个输入和输出，</span></span><br><span class="line"><span class="comment"># 根据chains中每个独立chain对象，和chains中的顺序，决定参数的传递，获取最终的输出结果</span></span><br><span class="line">overall_chain = SequentialChain(</span><br><span class="line">    chains=[chain1, chain2, chain3, chain4],</span><br><span class="line">    input_variables=[<span class="string">&quot;product_name&quot;</span>],</span><br><span class="line">    output_variables=[<span class="string">&quot;english_product_name&quot;</span>, <span class="string">&quot;english_introduce&quot;</span>, <span class="string">&quot;language&quot;</span>, <span class="string">&quot;summary&quot;</span>],</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">product_name = <span class="string">&quot;重庆小面&quot;</span></span><br><span class="line">res = overall_chain(product_name)</span><br></pre></td></tr></table></figure>

<p>创建步骤简单而言：</p>
<ol>
<li>n件事，先写n个LLMChain（提问的模版prompt + chain）</li>
<li>组建SequentialChain示例，指定chains、input_variables、output_variables三个必要参数</li>
</ol>
<ul>
<li>chains：n个chain，list格式</li>
<li>input_variables：输入变量，SequentialChain的最初输入</li>
<li>output_variables：所有的输出变量，SequentialChain的中间输出</li>
</ul>
<ol start="3">
<li><p>启动Chain，通过overall_chain传递输入的变量product_name</p>
</li>
<li><p>输出结果，结果由所有参数构成，字典dict格式。（这种输出方式，有助于代码工程化时的正确取值，dddd）</p>
</li>
</ol>
<h4 id="LLMRouterChain"><a href="#LLMRouterChain" class="headerlink" title="LLMRouterChain"></a>LLMRouterChain</h4><p>LLMRouterChain 是根据提示词的不同而选择不同的Chain进行执行，实现分支判断的作用。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/image-14.png" alt="alt text"></p>
<p><strong>构建流程：</strong><br>1.【Step1】初始化语言模型（”qwen:7b”)<br>2.【Step2】构建提示信息（json格式），包括：key、description 和 template</p>
<ul>
<li>【Step2.1】构建两个场景的模板</li>
<li>【Step2.2】构建提示信息</li>
</ul>
<p>3.【Step3】构建目标链chain_map（json格式），以提示信息prompt_infos中的key为key，以Chain为value<br>4.【Step4】构建路由链router_chain<br>5.【Step5】构建默认链 default_chain<br>6.【Step6】构建多提示链 MultiPromptChain</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains.llm <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.chains.router.llm_router <span class="keyword">import</span> LLMRouterChain, RouterOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain.chains.router.multi_prompt_prompt <span class="keyword">import</span> MULTI_PROMPT_ROUTER_TEMPLATE <span class="keyword">as</span> RounterTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment">## 【Step1】初始化语言模型</span></span><br><span class="line"><span class="comment"># from langchain.llms import OpenAI</span></span><br><span class="line"><span class="comment"># llm = OpenAI()</span></span><br><span class="line"><span class="comment"># llm = AzureChatOpenAI(deployment_name=&quot;GPT-4&quot;, temperature=0)</span></span><br><span class="line"></span><br><span class="line">ollama_llm = Ollama(model=<span class="string">&quot;qwen:7b&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 【Step2】构建提示信息（json格式），包括：key、description 和 template</span></span><br><span class="line"><span class="comment"># 【Step2.1】构建两个场景的模板</span></span><br><span class="line">flower_care_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个经验丰富的园丁，擅长解答关于养花育花的问题。</span></span><br><span class="line"><span class="string">下面是需要你来回答的问题:</span></span><br><span class="line"><span class="string">&#123;input&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">flower_deco_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一位网红插花大师，擅长解答关于鲜花装饰的问题。</span></span><br><span class="line"><span class="string">下面是需要你来回答的问题:</span></span><br><span class="line"><span class="string">&#123;input&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 【Step2.2】构建提示信息</span></span><br><span class="line">prompt_infos = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;key&quot;</span>: <span class="string">&quot;flower_care&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;适合回答关于鲜花护理的问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;template&quot;</span>: flower_care_template,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;key&quot;</span>: <span class="string">&quot;flower_decoration&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;适合回答关于鲜花装饰的问题&quot;</span>,</span><br><span class="line">        <span class="string">&quot;template&quot;</span>: flower_deco_template,</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 【Step3】构建目标链chain_map（json格式），以提示信息prompt_infos中的key为key，以Chain为value</span></span><br><span class="line">chain_map = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> info <span class="keyword">in</span> prompt_infos:</span><br><span class="line">    prompt = PromptTemplate(</span><br><span class="line">        template=info[<span class="string">&#x27;template&#x27;</span>],</span><br><span class="line">        input_variables=[<span class="string">&quot;input&quot;</span>] <span class="comment">#指定输入变量input</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;目标提示:\n&quot;</span>, prompt)</span><br><span class="line">    </span><br><span class="line">    chain = LLMChain(</span><br><span class="line">        llm=ollama_llm,</span><br><span class="line">        prompt=prompt,</span><br><span class="line">        verbose=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    chain_map[info[<span class="string">&quot;key&quot;</span>]] = chain</span><br><span class="line"></span><br><span class="line"><span class="comment">## 【Step4】构建路由链router_chain</span></span><br><span class="line">destinations = [<span class="string">f&quot;<span class="subst">&#123;p[<span class="string">&#x27;key&#x27;</span>]&#125;</span>: <span class="subst">&#123;p[<span class="string">&#x27;description&#x27;</span>]&#125;</span>&quot;</span> <span class="keyword">for</span> p <span class="keyword">in</span> prompt_infos]</span><br><span class="line">router_template = RounterTemplate.<span class="built_in">format</span>(destinations=<span class="string">&quot;\n&quot;</span>.join(destinations))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;路由模板:\n&quot;</span>, router_template)</span><br><span class="line"></span><br><span class="line">router_prompt = PromptTemplate(</span><br><span class="line">    template=router_template,</span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    output_parser=RouterOutputParser(), <span class="comment">#解析模型输出确定最佳目的地</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;路由提示:\n&quot;</span>, router_prompt)</span><br><span class="line"></span><br><span class="line">router_chain = LLMRouterChain.from_llm(</span><br><span class="line">    ollama_llm,</span><br><span class="line">    router_prompt,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 【Step5】构建默认链 default_chain </span></span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line">default_chain = ConversationChain(</span><br><span class="line">    llm=ollama_llm,</span><br><span class="line">    output_key=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 【Step6】构建多提示链 MultiPromptChain</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.router <span class="keyword">import</span> MultiPromptChain</span><br><span class="line"></span><br><span class="line">chain = MultiPromptChain(</span><br><span class="line">    router_chain=router_chain,</span><br><span class="line">    destination_chains=chain_map,</span><br><span class="line">    default_chain=default_chain,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试1</span></span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;如何为玫瑰浇水？&quot;</span>))</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_29950703/article/details/136216665">RouterChain相关应用，RouterChain可以将你的不同问题转发给不同专家链进行回答</a></p>
<h4 id="Memeory"><a href="#Memeory" class="headerlink" title="Memeory"></a>Memeory</h4><p>OpenAI提供的聊天接口 api，本身是不具备“记忆的”能力。如果想要使聊天具有记忆功能，则需要我们自行维护聊天记录，即每次把聊天记录发给语言模型。具体过程如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一次发送</span></span><br><span class="line">openai.ChatCompletion.create(</span><br><span class="line">  model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">  messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Hello&quot;</span>&#125;,</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="comment">#第二次发送</span></span><br><span class="line"></span><br><span class="line">openai.ChatCompletion.create(</span><br><span class="line">  model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">  messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Hello&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Hello, how can I help you?&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;who is more stylish Pikachu or Neo&quot;</span>&#125;,</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>只需要保存最近几次的聊天记录，LangChain提供Memory组件保存聊天记忆。</p>
<h5 id="使用Memory组件"><a href="#使用Memory组件" class="headerlink" title="使用Memory组件"></a>使用Memory组件</h5><h6 id="1-ChatMessageHistory"><a href="#1-ChatMessageHistory" class="headerlink" title="1. ChatMessageHistory"></a>1. ChatMessageHistory</h6><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">history = ChatMessageHistory()</span><br><span class="line">history.add_user_message(<span class="string">&quot;你好&quot;</span>)</span><br><span class="line">history.add_ai_message(<span class="string">&quot;你好?&quot;</span>)</span><br><span class="line">history.add_user_message(<span class="string">&quot;请问丹麦的首都是哪里?&quot;</span>)</span><br><span class="line">history.add_ai_message(<span class="string">&quot;哥本哈根&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(history.messages)</span><br><span class="line"></span><br><span class="line">ret = llm.invoke(history.messages)</span><br><span class="line"><span class="built_in">print</span>(ret)</span><br></pre></td></tr></table></figure>

<h5 id="2-ConversationBufferMemory"><a href="#2-ConversationBufferMemory" class="headerlink" title="2. ConversationBufferMemory"></a>2. ConversationBufferMemory</h5><p><code>ConversationBufferMemory</code>是<code>Langchain</code>框架中用于存储对话历史的一个内存组件。它类似于一个缓冲区，将对话中的所有消息（包括用户输入和AI响应）按照顺序存储起来，<strong>这样向LLM发送的消息就会带上最近几次的聊天记录了</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过 ConversationBufferMemory（缓冲记忆）可以实现最简单的记忆机制。</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.base <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line"></span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"></span><br><span class="line">conversation = ConversationChain(llm=llm,memory=ConversationBufferMemory())</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一天的对话</span></span><br><span class="line"><span class="comment">#回合1</span></span><br><span class="line">conversation.invoke(<span class="string">&quot;我姐姐明天要过生日，我需要一束生日花束。&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一次对话后的记忆:&quot;</span>, conversation.memory.buffer,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回合2</span></span><br><span class="line">conversation.invoke(<span class="string">&quot;她喜欢粉色玫瑰，颜色是粉色的。&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第二次对话后的记忆:&quot;</span>, conversation.memory.buffer,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回合3 （第二天的对话）</span></span><br><span class="line">conversation.invoke(<span class="string">&quot;我又来了，还记得我昨天为什么要来买花吗？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n第三次对话后时提示:\n&quot;</span>,conversation.prompt.template)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n第三次对话后的记忆:\n&quot;</span>, conversation.memory.buffer,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="3-ConversationBufferWindowMemory"><a href="#3-ConversationBufferWindowMemory" class="headerlink" title="3. ConversationBufferWindowMemory"></a>3. ConversationBufferWindowMemory</h5><p><code>ConversationBufferWindowMemory</code>基于滑动窗口的概念，只保留对话历史中的最近几轮交互。这种机制类似于人类的短期记忆，能够高效地管理对话上下文，同时减少内存占用。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实现一个最近的对话窗口，超过窗口条数的对话将被删除</span></span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span>  ConversationBufferWindowMemory</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferWindowMemory(k=<span class="number">5</span>) <span class="comment">#保存最近五次的对话窗口</span></span><br><span class="line"></span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>:<span class="string">&quot;你好，我是人类!&quot;</span>&#125;,&#123;<span class="string">&quot;output&quot;</span>:<span class="string">&quot;你好，我是AI，有什么可以帮助你的吗？&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>:<span class="string">&quot;我想吃鸭肉&quot;</span>&#125;,&#123;<span class="string">&quot;output&quot;</span>:<span class="string">&quot;好的，我帮你找找鸭肉的做法&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.buffer)</span><br></pre></td></tr></table></figure>

<h5 id="4-ConversationEntityMemory"><a href="#4-ConversationEntityMemory" class="headerlink" title="4. ConversationEntityMemory"></a>4. ConversationEntityMemory</h5><p> Langchain的Memory组件中的ConversationEntityMemory是一种特殊的记忆组件，它专注于跟踪和存储对话中提及的实体信息。 它通过识别对话中的实体（如人名、地名、产品名等），并将这些实体及其相关信息存储在内存中。</p>
<h5 id="5-ConversationKGMemory"><a href="#5-ConversationKGMemory" class="headerlink" title="5. ConversationKGMemory"></a>5. ConversationKGMemory</h5><p><code>ConversationKGMemory</code>是<code>Langchain</code>中的一个内存组件，它将对话历史中的关键信息（如实体、概念等）映射到知识图谱中，建立对话上下文与知识库之间的联系。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用知识图谱构建记忆</span></span><br><span class="line"><span class="comment"># from langchain.memory import ConversationKGMemory</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.memory.kg <span class="keyword">import</span> ConversationKGMemory</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">memory = ConversationKGMemory(llm=llm)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;say hi to dahuang&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;who is dahuang&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;dahuang is a dog name&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;okay&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;who is xiaohei&quot;</span>&#125;))</span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;who is dahuang&quot;</span>&#125;))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.get_knowledge_triplets(<span class="string">&quot;her favorite color is red&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.get_current_entities(<span class="string">&quot;what&#x27;s Sams favorite color?&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(memory.get_current_entities(<span class="string">&quot;穿着蓝色衣服、手里拿着冰糖葫芦的小明与小花正在去爬山&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(memory.get_current_entities(<span class="string">&quot;大壮的职业一个消防员&quot;</span>))</span><br></pre></td></tr></table></figure>

<h5 id="6-ConversationSummaryMemory"><a href="#6-ConversationSummaryMemory" class="headerlink" title="6. ConversationSummaryMemory"></a>6. ConversationSummaryMemory</h5><p>ConversationSummaryMemory通过对整个对话的内容进行总结，生成一个简洁的对话摘要，并记住这个摘要。</p>
<h4 id="在链上使用Memory"><a href="#在链上使用Memory" class="headerlink" title="在链上使用Memory"></a>在链上使用Memory</h4><h5 id="1-LLMChain上使用Memory"><a href="#1-LLMChain上使用Memory" class="headerlink" title="1. LLMChain上使用Memory"></a>1. LLMChain上使用Memory</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains.llm <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;你是一个机器人助理。</span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string">user:&#123;human_input&#125;</span></span><br><span class="line"><span class="string">AI:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt= PromptTemplate(</span><br><span class="line">    template=template,</span><br><span class="line">    input_variables=[<span class="string">&quot;chat_history&quot;</span>, <span class="string">&quot;human_input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = LLMChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    memory=memory,</span><br><span class="line">    prompt=prompt,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(chain.invoke(<span class="string">&quot;中国的首都是哪里？&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(chain.invoke(<span class="string">&quot;推荐一个旅游景点&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(chain.invoke(<span class="string">&quot;怎么去？&quot;</span>))</span><br></pre></td></tr></table></figure>

<h5 id="2-ConversationChain上使用Memory"><a href="#2-ConversationChain上使用Memory" class="headerlink" title="2. ConversationChain上使用Memory"></a>2. ConversationChain上使用Memory</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains.conversation.base <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;history&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">chain = ConversationChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    memory=memory</span><br><span class="line">)</span><br><span class="line">tp = &#123;</span><br><span class="line">    <span class="string">&quot;input&quot;</span>: <span class="string">&quot;给我讲一个笑话&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">chain.invoke(<span class="string">&quot;给我讲一个笑话&quot;</span>)</span><br><span class="line">chain.invoke(<span class="string">&quot;这个不好笑&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.buffer)</span><br></pre></td></tr></table></figure>

<h5 id="3-同一个链合并使用多个memory"><a href="#3-同一个链合并使用多个memory" class="headerlink" title="3. 同一个链合并使用多个memory"></a>3. 同一个链合并使用多个memory</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from langchain.Langchain_Chains import ConversationChain</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.base <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="comment"># from langchain.llms import OpenAI</span></span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> (</span><br><span class="line">    ConversationBufferMemory,</span><br><span class="line">    ConversationSummaryMemory,</span><br><span class="line">    CombinedMemory</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用CoversationSummaryMemory对对话进行总结</span></span><br><span class="line">summay = ConversationSummaryMemory(</span><br><span class="line">    llm=llm,</span><br><span class="line">    input_key=<span class="string">&quot;input&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">#使用ConversationBufferMemory对对话进行缓存</span></span><br><span class="line">cov_memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;history_now&quot;</span>,</span><br><span class="line">    input_key=<span class="string">&quot;input&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#合并使用多个memory</span></span><br><span class="line">memory = CombinedMemory(</span><br><span class="line">    memories=[summay, cov_memory],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">TEMPLATE = <span class="string">&quot;&quot;&quot;下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复&#x27;人类老爷，我真的不知道&#x27;.</span></span><br><span class="line"><span class="string">之前的对话摘要:</span></span><br><span class="line"><span class="string">&#123;history&#125;</span></span><br><span class="line"><span class="string">当前对话:</span></span><br><span class="line"><span class="string">&#123;history_now&#125;</span></span><br><span class="line"><span class="string">Human:&#123;input&#125;</span></span><br><span class="line"><span class="string">AI：&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=TEMPLATE,</span><br><span class="line">    input_variables=[<span class="string">&quot;history&quot;</span>, <span class="string">&quot;history_now&quot;</span>, <span class="string">&quot;input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = ConversationChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    memory=memory,</span><br><span class="line">    prompt=prompt</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;2024年NBA冠军是谁&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;介绍一下python语言&quot;</span>))</span><br></pre></td></tr></table></figure>

<h5 id="4-构建问答对话链"><a href="#4-构建问答对话链" class="headerlink" title="4. 构建问答对话链"></a>4. 构建问答对话链</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构建问答对话链</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains.question_answering <span class="keyword">import</span> load_qa_chain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Tongyi</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line">llm = Tongyi()</span><br><span class="line"></span><br><span class="line">docs = [Document(page_content=<span class="string">&#x27;这是一些无用的干扰项文本\n，这是一些无用的干扰项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本\n项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本\n项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本\n项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本\n项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本项文本，这是一些无用的干扰项文本\n在2025年NBA总决赛的最后一场比赛中，哈哈队在主场以94-89击败热火，以总比分4-1成功夺得NBA总冠军。这是球队历史上第一次获得总冠军，也是球队自1976年进入NBA以来的最佳成绩。哈哈队的成功主要归功于他们的领袖球员HAHA的出色表现。\n在总决赛的五场比赛中，HAHA展现出了惊人的统治力。他场均贡献30.2分、14个篮板和7.2次助攻，成为球队得分、篮板和助攻的核心。HAHA在进攻端展现出了全面的技术，他的得分能力和篮板能力让热火队无可奈何。同时，他还展现出了出色的组织能力，为球队创造了很多得分机会。\n在总决赛的最后一场比赛中，HAHA更是发挥出色。他在关键时刻承担责任，不仅在进攻端贡献了关键得分，还在防守端起到了重要作用。他的领导能力和稳定性为球队赢得了决胜的胜利。\nHAHA荣获总决赛最有价值球员（MVP）毫无悬念。他在总决赛中的出色表现让他成为了不可或缺的球队核心，也让他获得了职业生涯中的首个总冠军。这一荣誉不仅是对他个人努力的认可，也是对他带领球队取得成功的肯定。\n随着HAHA的崛起，哈哈队在过去几个赛季中逐渐崭露头角。他的全面发展和领导能力使他成为了球队的核心和灵魂人物。通过这次总决赛的胜利，孙健不仅实现了自己的篮球梦想，也为球队带来了无比的荣耀。\nHAHA带领哈哈队赢得2025年NBA总冠军，并凭借出色的表现获得总决赛最有价值球员（MVP）的荣誉。他在总决赛期间的统治力和全面能力使他成为球队的核心，同时也展现了他的领导才能。这次胜利不仅是HAHA个人职业生涯的里程碑，也是哈哈队迈向更高荣耀的关键一步。随着HAHA的领导，哈哈队有望在未来继续取得更多的成功。&#x27;</span>),]</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;下面是一段AI与人类的对话，AI会针对人类问题，提供尽可能详细的回答，如果AI不知道答案，会直接回复&#x27;人类老爷，我真的不知道&#x27;，参考一下相关文档以及历史对话信息，AI会据此组织最终回答内容.</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string">Human:&#123;human_input&#125;</span></span><br><span class="line"><span class="string">AI:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=template,</span><br><span class="line">    input_variables=[<span class="string">&quot;context&quot;</span>, <span class="string">&quot;chat_history&quot;</span>, <span class="string">&quot;human_input&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用ConversationBufferMemory对对话进行缓存</span></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    input_key=<span class="string">&quot;human_input&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载对话链</span></span><br><span class="line">chain = load_qa_chain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    memory=memory,</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    chain_type=<span class="string">&quot;stuff&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># chain.run(&quot;2024年NBA冠军是谁&quot;)</span></span><br><span class="line"><span class="comment"># chain(&#123;&quot;input_documents&quot;:docs,&quot;human_input&quot;:&quot;公司的营销策略是什么？&quot;&#125;)</span></span><br><span class="line"><span class="built_in">print</span>(chain(&#123;<span class="string">&quot;input_documents&quot;</span>: docs, <span class="string">&quot;human_input&quot;</span>: <span class="string">&quot;2025年NBA冠军是谁？&quot;</span>&#125;))</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.dpdpblog.online">DPDP</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.dpdpblog.online/2024/08/19/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%A5%E5%BF%97week02/">https://www.dpdpblog.online/2024/08/19/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%A5%E5%BF%97week02/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.dpdpblog.online" target="_blank">学习杂记</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/07/10/bivj2kSnGuJYqP9.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/08/26/%E5%90%8E%E7%AB%AF%E6%97%A5%E5%BF%97week04/" title="后端日志-week3"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/07/10/5iQM4IOeEqPs9oT.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">后端日志-week3</div></div></a></div><div class="next-post pull-right"><a href="/2024/08/19/%E5%90%8E%E7%AB%AF%E6%97%A5%E5%BF%97week03/" title="后端日志-week3"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2024/07/10/gWqLPHEyN5F1b27.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">后端日志-week3</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">DPDP</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ldphenshuai"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ldphenshuai" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#day01"><span class="toc-number">1.</span> <span class="toc-text">day01</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">大模型架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-MoE-%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B-%EF%BC%9A"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. MoE(混合专家模型)：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%9F%BA%E4%BA%8E%E6%A3%80%E7%B4%A2%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">2. 基于检索的模型:</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">检索增强生成的工作流程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Naive-RAG"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">Naive RAG</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Advanced-RAG-%E5%9C%A8Navive-RAG%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%E5%81%9A%E4%BA%86%E5%A2%9E%E5%BC%BA"><span class="toc-number">1.1.3.</span> <span class="toc-text">2.1 Advanced RAG(在Navive RAG的基础上做了增强)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-1-Pre-Retrieval-Proess-%E6%A3%80%E7%B4%A2%E5%89%8D%E4%BC%98%E5%8C%96"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">2.1.1 Pre-Retrieval Proess(检索前优化)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-2-Post-Retrieval-Process"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">2.1.2 Post-Retrieval Process</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Graph-RAG-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%92%8CRAG%E7%9A%84%E7%BB%93%E5%90%88%EF%BC%8C%E6%95%88%E6%9E%9C%E5%BE%88%E5%A5%BD"><span class="toc-number">1.1.3.3.</span> <span class="toc-text">Graph-RAG (知识图谱和RAG的结合，效果很好)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8BAdaptation"><span class="toc-number">1.2.</span> <span class="toc-text">大模型之Adaptation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84Adaptation"><span class="toc-number">1.2.1.</span> <span class="toc-text">为什么需要语言模型的Adaptation?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E6%A8%A1%E5%9E%8B%E9%80%82%E5%BA%94%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.2.2.</span> <span class="toc-text">微调模型适应任务</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E7%9A%84Adaptation%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">通用的Adaptation配置</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%BB%E6%B5%81%E7%9A%84Adaptation%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">主流的Adaptation方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-fine-tuning"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">1. fine-tuning</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">2. 大模型开发工具</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#day02"><span class="toc-number">2.</span> <span class="toc-text">day02</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LangChain%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.1.</span> <span class="toc-text">LangChain详解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LangChain%E7%BB%84%E6%88%90"><span class="toc-number">2.1.1.</span> <span class="toc-text">LangChain组成</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-Models"><span class="toc-number">2.1.1.1.</span> <span class="toc-text">1. Models</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-Embeddings"><span class="toc-number">2.1.1.2.</span> <span class="toc-text">2. Embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-LLMs"><span class="toc-number">2.1.1.3.</span> <span class="toc-text">3. LLMs</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Propmts"><span class="toc-number">2.1.2.</span> <span class="toc-text">4. Propmts</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#5-Few-Shot-example"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">5. Few-Shot example</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#indexes"><span class="toc-number">2.1.3.</span> <span class="toc-text">indexes</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#DocumentLoaer"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">DocumentLoaer</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#TexSplitter"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">TexSplitter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#VectorStores%E3%80%81Retrievers"><span class="toc-number">2.1.3.3.</span> <span class="toc-text">VectorStores、Retrievers</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chains"><span class="toc-number">2.1.4.</span> <span class="toc-text">Chains</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LLMChain"><span class="toc-number">2.1.5.</span> <span class="toc-text">LLMChain</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SimpleSequentialChain"><span class="toc-number">2.1.6.</span> <span class="toc-text">SimpleSequentialChain</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TransformChain"><span class="toc-number">2.1.7.</span> <span class="toc-text">TransformChain</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SequentialChain"><span class="toc-number">2.1.8.</span> <span class="toc-text">SequentialChain</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LLMRouterChain"><span class="toc-number">2.1.9.</span> <span class="toc-text">LLMRouterChain</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Memeory"><span class="toc-number">2.1.10.</span> <span class="toc-text">Memeory</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8Memory%E7%BB%84%E4%BB%B6"><span class="toc-number">2.1.10.1.</span> <span class="toc-text">使用Memory组件</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-ChatMessageHistory"><span class="toc-number">2.1.10.1.1.</span> <span class="toc-text">1. ChatMessageHistory</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-ConversationBufferMemory"><span class="toc-number">2.1.10.2.</span> <span class="toc-text">2. ConversationBufferMemory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-ConversationBufferWindowMemory"><span class="toc-number">2.1.10.3.</span> <span class="toc-text">3. ConversationBufferWindowMemory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-ConversationEntityMemory"><span class="toc-number">2.1.10.4.</span> <span class="toc-text">4. ConversationEntityMemory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-ConversationKGMemory"><span class="toc-number">2.1.10.5.</span> <span class="toc-text">5. ConversationKGMemory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-ConversationSummaryMemory"><span class="toc-number">2.1.10.6.</span> <span class="toc-text">6. ConversationSummaryMemory</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E9%93%BE%E4%B8%8A%E4%BD%BF%E7%94%A8Memory"><span class="toc-number">2.1.11.</span> <span class="toc-text">在链上使用Memory</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-LLMChain%E4%B8%8A%E4%BD%BF%E7%94%A8Memory"><span class="toc-number">2.1.11.1.</span> <span class="toc-text">1. LLMChain上使用Memory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-ConversationChain%E4%B8%8A%E4%BD%BF%E7%94%A8Memory"><span class="toc-number">2.1.11.2.</span> <span class="toc-text">2. ConversationChain上使用Memory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%90%8C%E4%B8%80%E4%B8%AA%E9%93%BE%E5%90%88%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AAmemory"><span class="toc-number">2.1.11.3.</span> <span class="toc-text">3. 同一个链合并使用多个memory</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E6%9E%84%E5%BB%BA%E9%97%AE%E7%AD%94%E5%AF%B9%E8%AF%9D%E9%93%BE"><span class="toc-number">2.1.11.4.</span> <span class="toc-text">4. 构建问答对话链</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2024 By DPDP</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">希望你还有旺盛的生活欲望。<p><a target="_blank" href="https://hexo.io/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://butterfly.js.org/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://www.jsdelivr.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用JsDelivr为静态资源提供CDN加速"></a> &nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站采用双线部署，默认线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Coding-0cedbe?style=flat&logo=Codio" title="本站采用双线部署，联通线路托管于Coding"></a>&nbsp;<a target="_blank" href="https://github.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/music/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>